<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Rene Mendoza Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Intro -->
					<div id="intro">
						<h1>Rene Mendoza<br />
						</h1>
						<p>Aspiring Data Engineer with experience building both relational and NoSQL databases, implementing ETL & data pipelines, deploying data warehouses and an IBM Data Engineering Certificate. <a href="https://www.linkedin.com/in/renemendoza/"><br />
						@Linkedin</a></p>
						<ul class="actions">
							<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
						</ul>
					</div>

				<!-- Header -->
				<header id="header">
					<a class="logo">Project #2</a>
				</header>


				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">MongoDB & Spark Project</a></li>
                            <li><a href="Tab2.html">Airflow Project</a></li>
                            <li class="active"><a href="Tab3.html">Kafka Project</a></li>
						</ul>
						<ul class="icons">
							<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
							<li><a href="https://www.linkedin.com/in/renemendoza/" class="icon brands alt fa-linkedin"><span class="label">linkedin</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Featured Post -->
							<article class="post featured">
								<header class="major">

									<h2><a>Data processing engine using Kafka<br />
									</a></h2>
									<p>In this project, we will take Spotify data, use Python to produce that data into a Kafka cluster, then consume the data and store it into AWS using a EC2 instance inside a S3 Bucket, crawl that data to build a glue data catalog and then analyse the data using Athena.<br />
									<br />
									</p>
								</header>
								<p>Workflow / Tech Stack</p>
								<a class="image main"><img src="images/Kafka_Project/Tech_Stack.jpg" alt="" /></a>
								<p>I created this playlist to use as our datasource.</p>
								<a class="image main"><img src="images/Spotify/SPOTIFY.jpg" alt="" /></a>
								<p>In my Airflow Project, we were able to create csv files in S3. We will utlitize that data as our data source for this project.</p>
								<a class="image main"><img src="images/Kafka_Project/CSV_2.jpg" alt="" /></a>
						

								<p>Create a EC2 instance in AWS, 'kafka_project_2'</p>
								<a class="image main"><img src="images/Kafka_Project/EC2_Status.jpg" alt="" /></a>
								<p>Connect to EC2 via SSH Client</p>
								<a class="image main"><img src="images/Kafka_Project/EC2_SSH_Client.jpg" alt="" /></a>
                                <p>Setup EC2 environment, download kafka to run kafka server</p>
								<a class="image main"><img src="images/Kafka_Project/EC2_Setup_Download_Kafka.jpg" alt="" /></a>
                                <p>Setup EC2 environment, download Java, kafka runs on top of java so we need to install java</p>
								<a class="image main"><img src="images/Kafka_Project/EC2_Setup_Download_Java.jpg" alt="" /></a>
								<a class="image main"><img src="images/Kafka_Project/EC2_Setup_Download_Java_2.jpg" alt="" /></a>

                                <p>Connect to Zookeeper server, Zookeeper helps manage the kafka cluster</p>
								<a class="image main"><img src="images/Kafka_Project/ZooKeeper_Connect.jpg" alt="" /></a>
                                <p>Connect to Kafka server</p>
								<a class="image main"><img src="images/Kafka_Project/Kafka_Connect.jpg" alt="" /></a>
								<p></p>
								<a class="image main"><img src="images/Kafka_Project/Kafka_Connect_2.jpg" alt="" /></a>

                                <p>Create topic 'demo_testing2', topics are like channels for organizing data.</p>
								<a class="image main"><img src="images/Kafka_Project/Topic_Create.jpg" alt="" /></a>
								<p>Create Producer 'demo_testing2', producers are responsible for sending data to those channels.<p>
							    <p>Create Consumer 'demo_testing2', consumers read data from those channels.</p>
								<p>Test connection 1</p>
								<a class="image main"><img src="images/Kafka_Project/Producer_Consumer_Test.jpg" alt="" /></a>

                                <p>Create Python Script to run Kafka producer/consumer, above we were manually sending data through kafka cluster for testing/demonstration purposes, now we must setup a script so that can be automated.</p>
								<p>After running Producer/Consumer, using the python script, test connection by pushing a few values through for testing purposes.</p>
								<a class="image main"><img src="images/Kafka_Project/Producer_Consumer_Test_JN_1.jpg" alt="" /></a>
								<a class="image main"><img src="images/Kafka_Project/Consumer_Index.jpg" alt="" /></a>
								<a class="image main"><img src="images/Kafka_Project/Producer_Consumer_Test3.jpg" alt="" /></a>
								<p>Now lets actually run python script as intended so it continously sends data from our spotify playist.</p>
								<a class="image main"><img src="images/Kafka_Project/Producer_Consumer_Test_JN_2.jpg" alt="" /></a>
								<p>We are now streaming, meaning data is continously being sent in real-time between producer and consumer as shown below.</p>
								<a class="image main"><img src="images/Kafka_Project/Producer_Consumer_Test_CL.jpg" alt="" /></a>
								
								<p>Now that we the kafka steam working, lets get this data into the cloud in a data lake.</p>

                                <p>Create data lake using AWS S3</p>
								<a class="image main"><img src="images/Kafka_Project/S3_Create.jpg" alt="" /></a>
                                <p>Run Kafka Straem to add data to S3</p>
								<a class="image main"><img src="images/Kafka_Project/S3_Add_Data.jpg" alt="" /></a>
								<p>Example of json file being created </p>
								<a class="image main"><img src="images/Kafka_Project/json_file_example.jpg" alt="" /></a>

                                <p>Create Crawler which allows us to be able to query the files/data inside our data lake.</p>
								<a class="image main"><img src="images/Kafka_Project/Crawler_Create.jpg" alt="" /></a>
                                <p>Create Database to house S3 data.</p>
								<a class="image main"><img src="images/Kafka_Project/Database_Create.jpg" alt="" /></a>

                                <p>Create S3 Bucket to store Athena query objects.</p>
								<a class="image main"><img src="images/Kafka_Project/Athena_Create_Bucket_0.jpg" alt="" /></a>
                                <p>Example of objects being stored, csv, metadata, etc.</p>
								<a class="image main"><img src="images/Kafka_Project/Athena_Create_Bucket_1.jpg" alt="" /></a>
                                <p>In Athena, test to see if we are able to run queries based on our data.</p>
								<a class="image main"><img src="images/Kafka_Project/Athena_Query_Success.jpg" alt="" /></a>
								<p>Query data and display results</p>
								<a class="image main"><img src="images/Kafka_Project/Athena_Final_Query_Results.jpg" alt="" /></a>
                                <p>Get count of rows in data</p>
								<a class="image main"><img src="images/Kafka_Project/Athena_Query_Results_Count_1.jpg" alt="" /></a>
                                <p>Get count of rows in data to demonstrate kafka stream is working.</p>
								<a class="image main"><img src="images/Kafka_Project/Athena_Query_Results_Count_2.jpg" alt="" /></a>
                                <p>Get count of rows in data to demonstrate kafka stream is working.</p>
								<a class="image main"><img src="images/Kafka_Project/Athena_Query_Results_Count_3.jpg" alt="" /></a>
                                <p>Get count of rows in data to demonstrate kafka stream is working.</p>
								<a class="image main"><img src="images/Kafka_Project/Athena_Query_Results_Count_4.jpg" alt="" /></a>








								<ul class="actions special">
									<li><a href="https://github.com/rmmbc1/Cousera_DE/blob/main/KafkaProducer.ipynb" class="button large">Producer</a></li>
									<li><a href="https://github.com/rmmbc1/Cousera_DE/blob/main/KafkaConsumer.ipynb" class="button large">Consumer</a></li>
								</ul>
							</article>		
		<!-- Footer -->
				<section class="split contact">
					<section class="alt">
						<h3>Address</h3>
						<p>Houston, TX</p>
					</section>
					<section>
						<h3>Email</h3>
						<p><a href="#">renemendoza113@gmail.com</a></p>
					</section>
					<section>
						<h3>Social</h3>
						<ul class="icons alt">
							<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
							<li><a href="https://www.linkedin.com/in/renemendoza/" class="icon brands alt fa-linkedin"><span class="label">linkedin</span></a></li>
					</section>
				</section>
			</footer>

		<!-- Copyright -->
			<div id="copyright">
				<ul><li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
			</div>

	</div>

<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>
</html>